{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#import sys\n",
    "#if len(sys.argv) != 4:\n",
    "#    print('Usage:')\n",
    "#    print('python train.py datacfg cfgfile weightfile')\n",
    "#    exit()\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import dataset\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "from utils import *\n",
    "from cfg import parse_cfg\n",
    "from region_loss import RegionLoss\n",
    "from darknet import Darknet\n",
    "from models.tiny_yolo import TinyYoloNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "datacfg       = 'cfg/voc.data'#sys.argv[1]\n",
    "#cfgfile       = 'cfg/tiny-yolo-voc.cfg'#sys.argv[2]\n",
    "cfgfile       = 'cfg/tiny-yolo-hackathon.cfg'\n",
    "#weightfile    = 'darknet19_448.conv.23'#sys.argv[3]\n",
    "weightfile    = 'yolov2-tiny-voc.weights'\n",
    "\n",
    "data_options  = read_data_cfg(datacfg)\n",
    "net_options   = parse_cfg(cfgfile)[0]\n",
    "\n",
    "trainlist     = data_options['train']\n",
    "testlist      = data_options['valid']\n",
    "backupdir     = data_options['backup']\n",
    "nsamples      = file_lines(trainlist)\n",
    "gpus          = data_options['gpus']  # e.g. 0,1,2,3\n",
    "ngpus         = len(gpus.split(','))\n",
    "num_workers   = int(data_options['num_workers'])\n",
    "\n",
    "batch_size    = int(net_options['batch'])\n",
    "max_batches   = int(net_options['max_batches'])\n",
    "learning_rate = float(net_options['learning_rate'])\n",
    "momentum      = float(net_options['momentum'])\n",
    "decay         = float(net_options['decay'])\n",
    "steps         = [float(step) for step in net_options['steps'].split(',')]\n",
    "scales        = [float(scale) for scale in net_options['scales'].split(',')]\n",
    "\n",
    "#Train parameters\n",
    "max_epochs    = max_batches*batch_size/nsamples+1\n",
    "use_cuda      = True\n",
    "seed          = int(time.time())\n",
    "eps           = 1e-5\n",
    "save_interval = 10  # epoches\n",
    "dot_interval  = 70  # batches\n",
    "\n",
    "# Test parameters\n",
    "conf_thresh   = 0.25\n",
    "nms_thresh    = 0.4\n",
    "iou_thresh    = 0.5\n",
    "\n",
    "if not os.path.exists(backupdir):\n",
    "    os.mkdir(backupdir)\n",
    "    \n",
    "###############\n",
    "torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = gpus\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "model       = Darknet(cfgfile)\n",
    "region_loss = model.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/yolo2_onnx/cfg.py:179: UserWarning: src is not broadcastable to dst, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n",
      "  conv_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_w])); start = start + num_w #20180615 modified for <= torch v0.3.0 post4\n",
      "/home/paperspace/yolo2_onnx/cfg.py:158: UserWarning: src is not broadcastable to dst, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n",
      "  conv_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_w])); start = start + num_w #20180615 modified for <= torch v0.3.0 post4\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(weightfile)\n",
    "#model.print_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2566400"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.seen = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_loss.seen  = model.seen\n",
    "processed_batches = model.seen/batch_size\n",
    "\n",
    "init_width        = model.width\n",
    "init_height       = model.height\n",
    "init_epoch        = model.seen/nsamples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_model = model\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset.listDataset(trainlist, shape=(init_width, init_height),\n",
    "                   shuffle=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                   ]), \n",
    "                   train=True, \n",
    "                   seen=cur_model.seen,\n",
    "                   batch_size=batch_size,\n",
    "                   num_workers=num_workers),\n",
    "    batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7ff32057feb8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data, target) = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = Variable(data), Variable(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_loss(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "??torch.utils.data.DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': num_workers, 'pin_memory': True} if use_cuda else {}\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset.listDataset(testlist, shape=(init_width, init_height),\n",
    "                   shuffle=False,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                   ]), train=False),\n",
    "    batch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "if use_cuda:\n",
    "    if ngpus > 1:\n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "    else:\n",
    "        model = model.cuda()\n",
    "\n",
    "params_dict = dict(model.named_parameters())\n",
    "params = []\n",
    "for key, value in params_dict.items():\n",
    "    if key.find('.bn') >= 0 or key.find('.bias') >= 0:\n",
    "        params += [{'params': [value], 'weight_decay': 0.0}]\n",
    "    else:\n",
    "        params += [{'params': [value], 'weight_decay': decay*batch_size}]\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate/batch_size, momentum=momentum, dampening=0, weight_decay=decay*batch_size)\n",
    "\n",
    "def adjust_learning_rate(optimizer, batch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = learning_rate\n",
    "    for i in range(len(steps)):\n",
    "        scale = scales[i] if i < len(scales) else 1\n",
    "        if batch >= steps[i]:\n",
    "            lr = lr * scale\n",
    "            if batch == steps[i]:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr/batch_size\n",
    "    return lr\n",
    "\n",
    "def train(epoch):\n",
    "    #pdb.set_trace()\n",
    "    global processed_batches\n",
    "    t0 = time.time()\n",
    "    if ngpus > 1:\n",
    "        cur_model = model.module\n",
    "    else:\n",
    "        cur_model = model\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset.listDataset(trainlist, shape=(init_width, init_height),\n",
    "                       shuffle=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                       ]), \n",
    "                       train=True, \n",
    "                       seen=cur_model.seen,\n",
    "                       batch_size=batch_size,\n",
    "                       num_workers=num_workers),\n",
    "        batch_size=batch_size, shuffle=False, drop_last=True, **kwargs)\n",
    "\n",
    "    lr = adjust_learning_rate(optimizer, processed_batches)\n",
    "    logging('epoch %d, processed %d samples, lr %f' % (epoch, epoch * len(train_loader.dataset), lr))\n",
    "    model.train()\n",
    "    t1 = time.time()\n",
    "    avg_time = torch.zeros(9)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        t2 = time.time()\n",
    "        adjust_learning_rate(optimizer, processed_batches)\n",
    "        processed_batches = processed_batches + 1\n",
    "        #if (batch_idx+1) % dot_interval == 0:\n",
    "        #    sys.stdout.write('.')\n",
    "\n",
    "        if use_cuda:\n",
    "            data = data.cuda()\n",
    "            #target= target.cuda()\n",
    "        t3 = time.time()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        t4 = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        t5 = time.time()\n",
    "        output = model(data)\n",
    "        t6 = time.time()\n",
    "        region_loss.seen = region_loss.seen + data.data.size(0)\n",
    "        loss = region_loss(output, target)\n",
    "        t7 = time.time()\n",
    "        loss.backward()\n",
    "        t8 = time.time()\n",
    "        optimizer.step()\n",
    "        t9 = time.time()\n",
    "        if False and batch_idx > 1:\n",
    "            avg_time[0] = avg_time[0] + (t2-t1)\n",
    "            avg_time[1] = avg_time[1] + (t3-t2)\n",
    "            avg_time[2] = avg_time[2] + (t4-t3)\n",
    "            avg_time[3] = avg_time[3] + (t5-t4)\n",
    "            avg_time[4] = avg_time[4] + (t6-t5)\n",
    "            avg_time[5] = avg_time[5] + (t7-t6)\n",
    "            avg_time[6] = avg_time[6] + (t8-t7)\n",
    "            avg_time[7] = avg_time[7] + (t9-t8)\n",
    "            avg_time[8] = avg_time[8] + (t9-t1)\n",
    "            print('-------------------------------')\n",
    "            print('       load data : %f' % (avg_time[0]/(batch_idx)))\n",
    "            print('     cpu to cuda : %f' % (avg_time[1]/(batch_idx)))\n",
    "            print('cuda to variable : %f' % (avg_time[2]/(batch_idx)))\n",
    "            print('       zero_grad : %f' % (avg_time[3]/(batch_idx)))\n",
    "            print(' forward feature : %f' % (avg_time[4]/(batch_idx)))\n",
    "            print('    forward loss : %f' % (avg_time[5]/(batch_idx)))\n",
    "            print('        backward : %f' % (avg_time[6]/(batch_idx)))\n",
    "            print('            step : %f' % (avg_time[7]/(batch_idx)))\n",
    "            print('           total : %f' % (avg_time[8]/(batch_idx)))\n",
    "        t1 = time.time()\n",
    "    print('')\n",
    "    t1 = time.time()\n",
    "    logging('training with %f samples/s' % (len(train_loader.dataset)/(t1-t0)))\n",
    "    if (epoch+1) % save_interval == 0:\n",
    "        logging('save weights to %s/%06d.weights' % (backupdir, epoch+1))\n",
    "        cur_model.seen = (epoch + 1) * len(train_loader.dataset)\n",
    "        cur_model.save_weights('%s/%06d.weights' % (backupdir, epoch+1))\n",
    "\n",
    "def test(epoch):\n",
    "    def truths_length(truths):\n",
    "        for i in range(50):\n",
    "            if truths[i][1] == 0:\n",
    "                return i\n",
    "\n",
    "    model.eval()\n",
    "    if ngpus > 1:\n",
    "        cur_model = model.module\n",
    "    else:\n",
    "        cur_model = model\n",
    "    num_classes = cur_model.num_classes\n",
    "    anchors     = cur_model.anchors\n",
    "    num_anchors = cur_model.num_anchors\n",
    "    total       = 0.0\n",
    "    proposals   = 0.0\n",
    "    correct     = 0.0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if use_cuda:\n",
    "            data = data.cuda()\n",
    "        data = Variable(data, volatile=True)\n",
    "        output = model(data).data\n",
    "        all_boxes = get_region_boxes(output, conf_thresh, num_classes, anchors, num_anchors)\n",
    "        for i in range(output.size(0)):\n",
    "            boxes = all_boxes[i]\n",
    "            boxes = nms(boxes, nms_thresh)\n",
    "            truths = target[i].view(-1, 5)\n",
    "            num_gts = truths_length(truths)\n",
    "     \n",
    "            total = total + num_gts\n",
    "    \n",
    "            for i in range(len(boxes)):\n",
    "                if boxes[i][4] > conf_thresh:\n",
    "                    proposals = proposals+1\n",
    "\n",
    "            for i in range(num_gts):\n",
    "                box_gt = [truths[i][1], truths[i][2], truths[i][3], truths[i][4], 1.0, 1.0, truths[i][0]]\n",
    "                best_iou = 0\n",
    "                best_j = -1\n",
    "                for j in range(len(boxes)):\n",
    "                    iou = bbox_iou(box_gt, boxes[j], x1y1x2y2=False)\n",
    "                    if iou > best_iou:\n",
    "                        best_j = j\n",
    "                        best_iou = iou\n",
    "                if best_iou > iou_thresh and boxes[best_j][6] == box_gt[6]:\n",
    "                    correct = correct+1\n",
    "\n",
    "    precision = 1.0*correct/(proposals+eps)\n",
    "    recall = 1.0*correct/(total+eps)\n",
    "    fscore = 2.0*precision*recall/(precision+recall+eps)\n",
    "    logging(\"precision: %f, recall: %f, fscore: %f\" % (precision, recall, fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-13 08:36:52 epoch 0, processed 0 samples, lr 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/tensor.py:305: UserWarning: self and other not broadcastable, but have the same number of elements.  Falling back to deprecated pointwise behavior.\n",
      "  return self.add(other)\n",
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/tensor.py:321: UserWarning: self and other not broadcastable, but have the same number of elements.  Falling back to deprecated pointwise behavior.\n",
      "  return self.mul(other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64: nGT 3, recall 0, proposals 100, loss: x 1021.271912, y 1926.883789, w 20105.025391, h 21047.841797, conf 4094.981934, cls 0.000000, total 48196.003906\n",
      "128: nGT 6, recall 0, proposals 238, loss: x 973.403259, y 1836.299927, w 27365.906250, h 27006.046875, conf 3231.294922, cls 0.000000, total 60412.953125\n",
      "192: nGT 5, recall 1, proposals 215, loss: x 855.554993, y 1688.666016, w 6209.292969, h 6484.882324, conf 2077.793213, cls 0.000000, total 17316.189453\n",
      "256: nGT 5, recall 0, proposals 99, loss: x 664.151428, y 1526.524170, w 22488.265625, h 24016.718750, conf 1161.247192, cls 0.000000, total 49856.906250\n",
      "320: nGT 3, recall 0, proposals 214, loss: x 531.396179, y 1290.569580, w 7340.053711, h 6874.397461, conf 673.365906, cls 0.000000, total 16709.783203\n",
      "384: nGT 6, recall 0, proposals 15, loss: x 404.449371, y 1144.697021, w 10856.240234, h 12685.431641, conf 395.857880, cls 0.000000, total 25486.675781\n",
      "448: nGT 3, recall 2, proposals 165, loss: x 339.718872, y 985.537964, w 11038.048828, h 12620.181641, conf 299.414276, cls 0.000000, total 25282.902344\n",
      "512: nGT 1, recall 0, proposals 114, loss: x 316.939453, y 831.512573, w 3968.134766, h 6323.220703, conf 195.978058, cls 0.000000, total 11635.786133\n",
      "576: nGT 10, recall 0, proposals 34, loss: x 318.421448, y 703.334473, w 8114.477051, h 8112.041504, conf 166.940399, cls 0.000000, total 17415.214844\n",
      "640: nGT 1, recall 0, proposals 60, loss: x 318.302277, y 569.699097, w 3170.594482, h 4469.960938, conf 166.338806, cls 0.000000, total 8694.895508\n",
      "704: nGT 9, recall 0, proposals 98, loss: x 297.303284, y 420.432678, w 4032.378906, h 5191.466309, conf 181.040939, cls 0.000000, total 10122.622070\n",
      "768: nGT 4, recall 0, proposals 193, loss: x 259.423828, y 355.484558, w 3740.986084, h 2437.819092, conf 248.096329, cls 0.000000, total 7041.810059\n",
      "832: nGT 5, recall 0, proposals 202, loss: x 228.266113, y 346.138092, w 1636.579712, h 3681.554443, conf 242.931290, cls 0.000000, total 6135.469238\n",
      "896: nGT 12, recall 3, proposals 58, loss: x 160.640228, y 310.323029, w 2687.817871, h 2213.428711, conf 293.643188, cls 0.000000, total 5665.853027\n",
      "960: nGT 11, recall 1, proposals 228, loss: x 130.453705, y 298.458130, w 1917.668457, h 2367.039551, conf 252.419495, cls 0.000000, total 4966.039551\n",
      "1024: nGT 9, recall 2, proposals 20, loss: x 117.810188, y 295.857788, w 1396.974365, h 1604.259155, conf 231.457458, cls 0.000000, total 3646.358887\n",
      "1088: nGT 3, recall 1, proposals 35, loss: x 117.174644, y 289.265869, w 1258.750732, h 1737.417114, conf 180.859619, cls 0.000000, total 3583.468018\n",
      "1152: nGT 7, recall 1, proposals 255, loss: x 102.990982, y 243.597824, w 1806.780396, h 1264.565063, conf 153.074097, cls 0.000000, total 3571.008301\n",
      "1216: nGT 3, recall 0, proposals 1, loss: x 95.266510, y 191.366486, w 932.043701, h 2050.112061, conf 105.903786, cls 0.000000, total 3374.692627\n",
      "1280: nGT 5, recall 0, proposals 251, loss: x 85.896805, y 155.208740, w 797.476624, h 650.584229, conf 90.471764, cls 0.000000, total 1779.638184\n",
      "1344: nGT 10, recall 0, proposals 136, loss: x 79.306656, y 140.200943, w 986.043823, h 1917.247314, conf 71.470695, cls 0.000000, total 3194.269531\n",
      "1408: nGT 12, recall 5, proposals 220, loss: x 63.559162, y 121.223221, w 646.652344, h 522.155762, conf 63.040722, cls 0.000000, total 1416.631226\n",
      "1472: nGT 5, recall 0, proposals 140, loss: x 52.094776, y 119.485458, w 696.912048, h 1728.984619, conf 52.058426, cls 0.000000, total 2649.535400\n",
      "1536: nGT 4, recall 0, proposals 113, loss: x 43.843174, y 119.811386, w 364.903320, h 233.622131, conf 46.132484, cls 0.000000, total 808.312500\n",
      "1600: nGT 8, recall 0, proposals 86, loss: x 41.430599, y 113.078018, w 732.937866, h 987.199951, conf 45.596130, cls 0.000000, total 1920.242676\n",
      "1664: nGT 5, recall 1, proposals 31, loss: x 42.918137, y 121.050621, w 456.778625, h 781.703064, conf 35.970413, cls 0.000000, total 1438.420898\n",
      "1728: nGT 1, recall 0, proposals 9, loss: x 40.620647, y 95.667870, w 287.966461, h 563.832336, conf 34.413548, cls 0.000000, total 1022.500854\n",
      "1792: nGT 6, recall 2, proposals 59, loss: x 39.390202, y 84.340424, w 585.263306, h 747.629150, conf 42.349197, cls 0.000000, total 1498.972290\n",
      "1856: nGT 15, recall 2, proposals 12, loss: x 34.986320, y 60.486198, w 307.504639, h 435.960785, conf 39.967155, cls 0.000000, total 878.905151\n",
      "1920: nGT 12, recall 1, proposals 8, loss: x 36.666317, y 51.923462, w 371.761292, h 766.705200, conf 28.700899, cls 0.000000, total 1255.757202\n",
      "1984: nGT 3, recall 1, proposals 33, loss: x 29.731798, y 33.404064, w 163.389481, h 99.014603, conf 32.799576, cls 0.000000, total 358.339539\n",
      "2048: nGT 8, recall 2, proposals 32, loss: x 27.219749, y 29.417614, w 336.625580, h 553.871643, conf 31.593990, cls 0.000000, total 978.728577\n",
      "2112: nGT 8, recall 1, proposals 9, loss: x 24.274391, y 33.246799, w 175.104279, h 313.452515, conf 31.481304, cls 0.000000, total 577.559326\n",
      "2176: nGT 1, recall 0, proposals 20, loss: x 24.220230, y 35.464302, w 113.110611, h 222.327637, conf 31.506142, cls 0.000000, total 426.628906\n",
      "2240: nGT 7, recall 0, proposals 18, loss: x 23.134270, y 37.214554, w 218.672638, h 332.455505, conf 28.474819, cls 0.000000, total 639.951721\n",
      "2304: nGT 13, recall 0, proposals 33, loss: x 23.810610, y 40.198719, w 149.304077, h 168.478851, conf 36.414421, cls 0.000000, total 418.206696\n",
      "2368: nGT 7, recall 2, proposals 9, loss: x 20.431868, y 31.355785, w 147.091064, h 303.504089, conf 34.192238, cls 0.000000, total 536.575073\n",
      "2432: nGT 4, recall 1, proposals 82, loss: x 17.922096, y 28.130085, w 76.566010, h 104.141510, conf 40.844563, cls 0.000000, total 267.604279\n",
      "2496: nGT 3, recall 0, proposals 38, loss: x 19.180637, y 22.682299, w 92.634727, h 140.695419, conf 36.765842, cls 0.000000, total 311.958923\n",
      "\n",
      "2018-07-13 08:37:28 training with 67.913981 samples/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/yolo2_onnx/utils.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  cls_confs = torch.nn.Softmax()(Variable(output[5:5+num_classes].transpose(0,1))).data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-13 08:37:55 precision: 0.000000, recall: 0.000000, fscore: 0.000000\n"
     ]
    }
   ],
   "source": [
    "evaluate = False\n",
    "if evaluate:\n",
    "    logging('evaluating ...')\n",
    "    test(0)\n",
    "else:\n",
    "#    for epoch in range(int(init_epoch), int(max_epochs)): \n",
    "    for epoch in range(int(init_epoch), int(1)): \n",
    "        train(epoch)\n",
    "        test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
